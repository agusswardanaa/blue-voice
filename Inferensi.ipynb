{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea01057",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126833e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9efa5",
   "metadata": {},
   "source": [
    "## Fungsi untuk Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575552df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
    "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
    " \n",
    "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
    "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
    "    return text\n",
    " \n",
    "def casefolding_text(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    return text\n",
    " \n",
    "def tokenizing_text(text): # Memecah atau membagi string, teks menjadi daftar token\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    " \n",
    "def filtering_text(text): # Menghapus stopwords dalam teks\n",
    "    listStopwords = set(stopwords.words('english'))\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    " \n",
    "def to_sentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3da83b",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb44e7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "tfidf_attractions = joblib.load(\"models/tfidf_attractions.pkl\")\n",
    "tfidf_amenities = joblib.load(\"models/tfidf_amenities.pkl\")\n",
    "tfidf_access = joblib.load(\"models/tfidf_access.pkl\")\n",
    "tfidf_price = joblib.load(\"models/tfidf_price.pkl\")\n",
    "tfidf_no_aspect = joblib.load(\"models/tfidf_no_aspect.pkl\")\n",
    "\n",
    "model_attractions = load_model(\"models/nn_attractions.h5\")\n",
    "model_amenities = load_model(\"models/nn_amenities.h5\")\n",
    "model_access = load_model(\"models/nn_access.h5\")\n",
    "model_price = load_model(\"models/nn_price.h5\")\n",
    "model_no_aspect = load_model(\"models/nn_no_aspect.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419b847",
   "metadata": {},
   "source": [
    "## Fungsi untuk Inferensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95df0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Preprocessing\n",
    "    text = cleaning_text(text)\n",
    "    text = casefolding_text(text)\n",
    "    text = tokenizing_text(text)\n",
    "    text = filtering_text(text)\n",
    "    text = to_sentence(text)\n",
    "\n",
    "    # Transformasi teks ke dalam bentuk TF-IDF\n",
    "    tfidf_attractions_text = tfidf_attractions.transform([text])\n",
    "    tfidf_amenities_text = tfidf_amenities.transform([text])\n",
    "    tfidf_access_text = tfidf_access.transform([text])\n",
    "    tfidf_price_text = tfidf_price.transform([text])\n",
    "    tfidf_no_aspect_text = tfidf_no_aspect.transform([text])\n",
    "\n",
    "    # Prediksi\n",
    "    prediction_attractions = model_attractions.predict(tfidf_attractions_text, verbose=0)\n",
    "    prediction_amenities = model_amenities.predict(tfidf_amenities_text, verbose=0)\n",
    "    prediction_access = model_access.predict(tfidf_access_text, verbose=0)\n",
    "    prediction_price = model_price.predict(tfidf_price_text, verbose=0)\n",
    "    prediction_no_aspect = model_no_aspect.predict(tfidf_no_aspect_text, verbose=0)\n",
    "\n",
    "    sentiment_attractions = np.argmax(prediction_attractions, axis=1)[0]\n",
    "    sentiment_amenities = np.argmax(prediction_amenities, axis=1)[0]\n",
    "    sentiment_access = np.argmax(prediction_access, axis=1)[0]\n",
    "    sentiment_price = np.argmax(prediction_price, axis=1)[0]\n",
    "    sentiment_no_aspect = np.argmax(prediction_no_aspect, axis=1)[0]\n",
    "\n",
    "    label_map = {\n",
    "        0: \"negative\",\n",
    "        1: \"neutral\",\n",
    "        2: \"positive\",\n",
    "        3: \"none\"\n",
    "    }\n",
    "    \n",
    "    sentiment_attractions = label_map[sentiment_attractions]\n",
    "    sentiment_amenities = label_map[sentiment_amenities]\n",
    "    sentiment_access = label_map[sentiment_access]\n",
    "    sentiment_price = label_map[sentiment_price]\n",
    "    sentiment_no_aspect = label_map[sentiment_no_aspect]\n",
    "\n",
    "    return {\n",
    "        \"attractions\": sentiment_attractions,\n",
    "        \"amenities\": sentiment_amenities,\n",
    "        \"access\": sentiment_access,\n",
    "        \"price\": sentiment_price,\n",
    "        \"no_aspect\": sentiment_no_aspect\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d30d46d",
   "metadata": {},
   "source": [
    "## Contoh Inferensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ee477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D418471310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D418471310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Pemandangan pantainya indah sekali dan tiket masuknya murah\"\n",
    "text_2 = \"pantainya kotor dan banyak sampah berserakan\"\n",
    "text_3 = \"Jalan menuju pantainya bagus dan mudah diakses\"\n",
    "\n",
    "prediction_1 = predict_sentiment(text_1)\n",
    "prediction_2 = predict_sentiment(text_2)\n",
    "prediction_3 = predict_sentiment(text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867cc655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Pemandangan pantainya indah sekali dan tiket masuknya murah - Output: {'attractions': 'none', 'amenities': 'none', 'access': 'none', 'price': 'positive', 'no_aspect': 'none'}\n",
      "Input: pantainya kotor dan banyak sampah berserakan - Output: {'attractions': 'negative', 'amenities': 'negative', 'access': 'none', 'price': 'none', 'no_aspect': 'none'}\n",
      "Input: Jalan menuju pantainya bagus dan mudah diakses - Output: {'attractions': 'positive', 'amenities': 'none', 'access': 'positive', 'price': 'none', 'no_aspect': 'none'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input: {text_1} - Output: {prediction_1}\")\n",
    "print(f\"Input: {text_2} - Output: {prediction_2}\")\n",
    "print(f\"Input: {text_3} - Output: {prediction_3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
